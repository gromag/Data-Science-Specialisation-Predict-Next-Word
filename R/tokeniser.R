#Tokenization - identifying appropriate tokens such as words, punctuation, and numbers. 
#Writing a function that takes a file as input and returns a tokenized version of it.